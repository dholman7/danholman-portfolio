name: Portfolio Test Suite with Coverage

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      module:
        type: choice
        options:
          - all
          - automation-framework
          - ai-rulesets
          - cloud-native-app
          - react-playwright-demo
        required: true
        default: all
        description: Module to test (or 'all' for complete test suite)
      test_type:
        type: choice
        options:
          - all
          - unit
          - component
          - integration
          - e2e
          - performance
        required: true
        default: all
        description: Type of tests to run
      include_allure:
        type: boolean
        required: false
        default: true
        description: Generate Allure reports
      enable_cursor_fixes:
        type: boolean
        required: false
        default: true
        description: Enable Cursor CLI to automatically fix test failures

# Sets permissions for GitHub Pages deployment
permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  automation-framework:
    name: Automation Framework (Python)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.module == 'all' || github.event.inputs.module == 'automation-framework' || github.event_name != 'workflow_dispatch' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      - name: Install Cursor CLI
        if: ${{ github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch' }}
        run: |
          curl https://cursor.com/install -fsS | bash
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
      - run: |
          if [ -f automation-framework/requirements.txt ]; then pip install -r automation-framework/requirements.txt; fi
          if [ -f automation-framework/pyproject.toml ]; then pip install -e "automation-framework[test]"; fi
          # Install Allure dependencies
          pip install allure-pytest allure-python-commons
          # Install additional test dependencies
          pip install pytest-cov pytest-html
          # Create reports directory
          mkdir -p automation-framework/reports/allure-results automation-framework/reports/coverage
      - run: |
          if command -v ruff >/dev/null 2>&1; then ruff check automation-framework/ || true; fi
          if command -v black >/dev/null 2>&1; then black --check automation-framework/ || true; fi
      - name: Run Tests with Allure Results and Coverage
        if: always()
        run: |
          # Run tests based on test_type input with Allure reporting and coverage
          echo "Running tests for type: ${{ github.event.inputs.test_type || 'all' }}"
          cd automation-framework
          if [ "${{ github.event.inputs.test_type || 'all' }}" = "all" ] || [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            echo "Running all tests with Allure reporting and coverage..."
            pytest --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || true
          elif [ "${{ github.event.inputs.test_type }}" = "unit" ]; then
            echo "Running unit tests with Allure reporting and coverage..."
            pytest tests/unit/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "component" ]; then
            echo "Running component tests with Allure reporting and coverage..."
            pytest tests/component/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "integration" ]; then
            echo "Running integration tests with Allure reporting and coverage..."
            pytest tests/integration/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "e2e" ]; then
            echo "Running e2e tests with Allure reporting and coverage..."
            pytest tests/e2e/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "performance" ]; then
            echo "Running performance tests with Allure reporting and coverage..."
            pytest tests/performance/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          fi
          
          # List generated files for debugging
          echo "Allure results directory contents:"
          ls -la reports/allure-results/ || echo "No Allure results generated"
          echo "Coverage reports directory contents:"
          ls -la reports/coverage/ || echo "No coverage reports generated"
          echo "Reports directory structure:"
          find reports/ -type f -name "*.json" | head -10 || echo "No JSON files found"
          echo "Allure results file count:"
          find reports/allure-results/ -name "*.json" | wc -l || echo "0"
          echo "Sample Allure result files:"
          find reports/allure-results/ -name "*.json" | head -5 || echo "No Allure JSON files found"
      - name: Ensure Coverage Report Generation
        if: always()
        run: |
          echo "Ensuring coverage report is generated..."
          cd automation-framework
          # If coverage directory doesn't exist or is empty, generate it from unit tests
          if [ ! -d "reports/coverage" ] || [ ! "$(ls -A reports/coverage)" ]; then
            echo "Coverage directory missing or empty, generating from unit tests..."
            pytest tests/unit/ --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || echo "Unit test coverage generation failed"
          fi
          echo "Final coverage directory contents:"
          ls -la reports/coverage/ || echo "No coverage directory found"
      - name: Fix Test Failures with Cursor
        id: cursor-fixes
        if: failure() && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing test failures..."
          cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the test failures in this CI run and fix the test files in the automation-framework module. 
          This module uses Python with pytest, selenium, and API testing frameworks.
          Focus on fixing import errors, method name mismatches, API compatibility issues, test logic problems, and pytest configuration issues. 
          Ensure all tests can be collected and executed successfully."
          
      - name: Fix CI/CD Issues with Cursor
        id: cursor-cicd-fixes
        if: always() && (failure() || github.event.inputs.enable_cursor_fixes == 'true')
        timeout-minutes: 5
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing CI/CD issues..."
          timeout 300 cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the CI/CD pipeline issues in this run, particularly:
          1. Artifact upload/download problems
          2. Allure report generation failures
          3. Coverage report generation issues
          4. GitHub Pages deployment problems
          5. Path resolution issues in deploy workflows

          Check the automation-framework module for:
          - Allure report generation in reports/allure-report/
          - Coverage report generation in reports/coverage/
          - Artifact upload paths and naming
          - Test execution and reporting configuration

          Fix any issues that prevent proper artifact generation and deployment to GitHub Pages.
          Focus on ensuring reports are generated correctly and artifacts are uploaded with proper paths." || echo "Cursor CLI timeout or error - continuing workflow"
      - name: Re-run Tests After Cursor Fixes
        if: always() && (steps.cursor-fixes.outcome == 'success' || steps.cursor-fixes.outcome == 'failure') && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        run: |
          echo "ðŸ”„ Re-running tests after Cursor fixes..."
          pytest --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || true
      - name: Generate Allure Report
        if: always()
        run: |
          cd automation-framework
          if [ -d "reports/allure-results" ] && [ "$(ls -A reports/allure-results)" ]; then
            echo "Installing Allure commandline..."
            # Install Allure using npm (more reliable than yarn global)
            npm install -g allure-commandline
            echo "Generating Allure report for automation-framework..."
            allure generate reports/allure-results --clean -o reports/allure-report
            echo "Allure report generated successfully"
            # Verify the report was created
            if [ -d "reports/allure-report" ]; then
              echo "Allure report directory created successfully"
              ls -la reports/allure-report/
            else
              echo "ERROR: Allure report directory was not created"
            fi
          else
            echo "No Allure results found for automation-framework"
          fi

      - name: Upload Allure Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: automation-framework-allure-results
          path: automation-framework/reports/allure-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: automation-framework-allure-report
          path: automation-framework/reports/allure-report/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: automation-framework-coverage-report
          path: automation-framework/reports/coverage/
          retention-days: 30
          if-no-files-found: warn

  ai-rulesets:
    name: AI Rulesets (Python)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.module == 'all' || github.event.inputs.module == 'ai-rulesets' || github.event_name != 'workflow_dispatch' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      - name: Install Cursor CLI
        if: ${{ github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch' }}
        run: |
          curl https://cursor.com/install -fsS | bash
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
      - run: |
          if [ -f ai-rulesets/requirements.txt ]; then pip install -r ai-rulesets/requirements.txt; fi
          if [ -f ai-rulesets/pyproject.toml ]; then pip install -e "ai-rulesets[dev]"; fi
          # Install Allure dependencies
          pip install allure-pytest allure-python-commons
          # Install additional test dependencies
          pip install pytest-cov pytest-html
          # Create reports directory
          mkdir -p ai-rulesets/reports/allure-results ai-rulesets/reports/coverage
      - run: |
          if command -v ruff >/dev/null 2>&1; then ruff check ai-rulesets/ || true; fi
          if command -v black >/dev/null 2>&1; then black --check ai-rulesets/ || true; fi
      - name: Run Tests with Allure Results and Coverage
        if: always()
        run: |
          # Run tests based on test_type input with Allure reporting and coverage
          echo "Running tests for type: ${{ github.event.inputs.test_type || 'all' }}"
          cd ai-rulesets
          if [ "${{ github.event.inputs.test_type || 'all' }}" = "all" ] || [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            echo "Running all tests with Allure reporting and coverage..."
            pytest --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || true
          elif [ "${{ github.event.inputs.test_type }}" = "unit" ]; then
            echo "Running unit tests with Allure reporting and coverage..."
            pytest tests/unit/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "component" ]; then
            echo "Running component tests with Allure reporting and coverage..."
            pytest tests/component/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "integration" ]; then
            echo "Running integration tests with Allure reporting and coverage..."
            pytest tests/integration/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "e2e" ]; then
            echo "Running e2e tests with Allure reporting and coverage..."
            pytest tests/e2e/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          elif [ "${{ github.event.inputs.test_type }}" = "performance" ]; then
            echo "Running performance tests with Allure reporting and coverage..."
            pytest tests/performance/ -v --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml || true
          fi
          
          # List generated files for debugging
          echo "Allure results directory contents:"
          ls -la reports/allure-results/ || echo "No Allure results generated"
          echo "Coverage reports directory contents:"
          ls -la reports/coverage/ || echo "No coverage reports generated"
          echo "Reports directory structure:"
          find reports/ -type f -name "*.json" | head -10 || echo "No JSON files found"
          echo "Allure results file count:"
          find reports/allure-results/ -name "*.json" | wc -l || echo "0"
          echo "Sample Allure result files:"
          find reports/allure-results/ -name "*.json" | head -5 || echo "No Allure JSON files found"
      - name: Ensure Coverage Report Generation
        if: always()
        run: |
          echo "Ensuring coverage report is generated..."
          cd automation-framework
          # If coverage directory doesn't exist or is empty, generate it from unit tests
          if [ ! -d "reports/coverage" ] || [ ! "$(ls -A reports/coverage)" ]; then
            echo "Coverage directory missing or empty, generating from unit tests..."
            pytest tests/unit/ --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || echo "Unit test coverage generation failed"
          fi
          echo "Final coverage directory contents:"
          ls -la reports/coverage/ || echo "No coverage directory found"
          # Copy coverage to reports/coverage for consistency with other modules
          if [ -d "coverage" ] && [ "$(ls -A coverage)" ]; then
            echo "Copying coverage to reports/coverage for consistency..."
            mkdir -p reports/coverage
            cp -r coverage/* reports/coverage/
          fi
      - name: Fix Test Failures with Cursor
        id: cursor-fixes
        if: failure() && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing test failures..."
          cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the test failures in this CI run and fix the test files in the ai-rulesets module. 
          This module uses Python with pytest, ruff, black, and mypy for code quality and testing.
          Focus on fixing import errors, method name mismatches, API compatibility issues, test logic problems, and pytest configuration issues. 
          Ensure all tests can be collected and executed successfully."
          
      - name: Fix CI/CD Issues with Cursor
        id: cursor-cicd-fixes
        if: always() && (failure() || github.event.inputs.enable_cursor_fixes == 'true')
        timeout-minutes: 5
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing CI/CD issues..."
          timeout 300 cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the CI/CD pipeline issues in this run, particularly:
          1. Artifact upload/download problems
          2. Allure report generation failures
          3. Coverage report generation issues
          4. GitHub Pages deployment problems
          5. Path resolution issues in deploy workflows

          Check the ai-rulesets module for:
          - Allure report generation in reports/allure-report/
          - Coverage report generation in reports/coverage/
          - Artifact upload paths and naming
          - Test execution and reporting configuration

          Fix any issues that prevent proper artifact generation and deployment to GitHub Pages.
          Focus on ensuring reports are generated correctly and artifacts are uploaded with proper paths." || echo "Cursor CLI timeout or error - continuing workflow"
      - name: Re-run Tests After Cursor Fixes
        if: always() && (steps.cursor-fixes.outcome == 'success' || steps.cursor-fixes.outcome == 'failure') && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        run: |
          echo "ðŸ”„ Re-running tests after Cursor fixes..."
          pytest --alluredir=reports/allure-results --cov=src --cov-report=html:reports/coverage --cov-report=xml:reports/coverage.xml -v || true
      - name: Generate Allure Report
        if: always()
        run: |
          cd ai-rulesets
          if [ -d "reports/allure-results" ] && [ "$(ls -A reports/allure-results)" ]; then
            echo "Installing Allure commandline..."
            # Install Allure using npm (more reliable than yarn global)
            npm install -g allure-commandline
            echo "Generating Allure report for ai-rulesets..."
            allure generate reports/allure-results --clean -o reports/allure-report
            echo "Allure report generated successfully"
            # Verify the report was created
            if [ -d "reports/allure-report" ]; then
              echo "Allure report directory created successfully"
              ls -la reports/allure-report/
            else
              echo "ERROR: Allure report directory was not created"
            fi
          else
            echo "No Allure results found for ai-rulesets"
          fi

      - name: Upload Allure Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-rulesets-allure-results
          path: ai-rulesets/reports/allure-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-rulesets-allure-report
          path: ai-rulesets/reports/allure-report/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-rulesets-coverage-report
          path: ai-rulesets/reports/coverage/
          retention-days: 30
          if-no-files-found: warn

  cloud-native-app:
    name: Cloud Native App (TypeScript)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.module == 'all' || github.event.inputs.module == 'cloud-native-app' || github.event_name != 'workflow_dispatch' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20.19.0'
      - name: Install Cursor CLI
        if: ${{ github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch' }}
        run: |
          curl https://cursor.com/install -fsS | bash
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
      - run: |
          # Install Node.js dependencies for cloud-native-app
          cd cloud-native-app
          if [ -f package.json ]; then 
            echo "Installing cloud-native-app dependencies..."
            yarn install
          fi
          # Create reports directory in cloud-native-app
          mkdir -p reports/allure-results reports/coverage
      - run: |
          cd cloud-native-app
          if command -v yarn >/dev/null 2>&1; then yarn lint || true; fi
      - name: Run Tests with Allure Results and Coverage
        if: always()
        run: |
          cd cloud-native-app
          # Create reports directory
          mkdir -p reports/allure-results reports/coverage
          
          # Run TypeScript/Jest tests with Allure reporting and coverage
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            echo "Running TypeScript/Jest tests with Allure reporting and coverage..."
            yarn test:coverage || true
            echo "Running Jest tests with Allure results generation..."
            yarn test || true
          fi
          
          # List generated files for debugging
          echo "Allure results directory contents:"
          ls -la reports/allure-results/ || echo "No Allure results generated"
          echo "Coverage reports directory contents:"
          ls -la coverage/ || echo "No coverage reports generated"
          echo "Reports directory structure:"
          find reports/ -type f -name "*.json" | head -10 || echo "No JSON files found"
          echo "Allure results file count:"
          find reports/allure-results/ -name "*.json" | wc -l || echo "0"
          echo "Sample Allure result files:"
          find reports/allure-results/ -name "*.json" | head -5 || echo "No Allure JSON files found"
      - name: Ensure Coverage Report Generation
        if: always()
        run: |
          echo "Ensuring coverage report is generated for cloud-native-app..."
          cd cloud-native-app
          # If coverage directory doesn't exist or is empty, generate it from Jest tests
          if [ ! -d "coverage" ] || [ ! "$(ls -A coverage)" ]; then
            echo "Coverage directory missing or empty, generating from Jest tests..."
            if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
              yarn test:coverage || echo "Jest test coverage generation failed"
            fi
          fi
          echo "Final coverage directory contents:"
          ls -la coverage/ || echo "No coverage directory found"
          # Copy coverage to reports/coverage for consistency with other modules
          if [ -d "coverage" ] && [ "$(ls -A coverage)" ]; then
            echo "Copying coverage to reports/coverage for consistency..."
            mkdir -p reports/coverage
            cp -r coverage/* reports/coverage/
          fi
      - name: Fix Test Failures with Cursor
        id: cursor-fixes
        if: failure() && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing test failures..."
          cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the test failures in this CI run and fix the test files in the cloud-native-app module. 
          This module uses TypeScript/Node.js with Jest for testing and Python with pytest for regression tests.
          Focus on fixing TypeScript errors, Jest configuration issues, import errors, method name mismatches, API compatibility issues, and test logic problems. 
          Ensure all tests can be collected and executed successfully."
          
      - name: Fix CI/CD Issues with Cursor
        id: cursor-cicd-fixes
        if: always() && (failure() || github.event.inputs.enable_cursor_fixes == 'true')
        timeout-minutes: 5
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing CI/CD issues..."
          timeout 300 cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the CI/CD pipeline issues in this run, particularly:
          1. Artifact upload/download problems
          2. Allure report generation failures
          3. Coverage report generation issues
          4. GitHub Pages deployment problems
          5. Path resolution issues in deploy workflows
          
          Check the cloud-native-app module for:
          - Allure report generation in reports/allure-report/
          - Coverage report generation in reports/coverage/
          - Artifact upload paths and naming
          - Test execution and reporting configuration
          - TypeScript/Jest test configuration
          
          Fix any issues that prevent proper artifact generation and deployment to GitHub Pages.
          Focus on ensuring reports are generated correctly and artifacts are uploaded with proper paths." || echo "Cursor CLI timeout or error - continuing workflow"
      - name: Re-run Tests After Cursor Fixes
        if: always() && (steps.cursor-fixes.outcome == 'success' || steps.cursor-fixes.outcome == 'failure') && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        run: |
          echo "ðŸ”„ Re-running tests after Cursor fixes..."
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            yarn test:coverage || true
          fi
      - name: Generate Allure Report
        if: always()
        run: |
          cd cloud-native-app
          if [ -d "allure-results" ] && [ "$(ls -A allure-results)" ]; then
            echo "Installing Allure commandline..."
            # Install Allure using npm (more reliable than yarn global)
            npm install -g allure-commandline
            echo "Generating Allure report for cloud-native-app..."
            allure generate allure-results --clean -o allure-report
            echo "Allure report generated successfully"
            # Verify the report was created
            if [ -d "allure-report" ]; then
              echo "Allure report directory created successfully"
              ls -la allure-report/
            else
              echo "ERROR: Allure report directory was not created"
            fi
          else
            echo "No Allure results found for cloud-native-app"
          fi

      - name: Upload Allure Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cloud-native-app-allure-results
          path: cloud-native-app/allure-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cloud-native-app-allure-report
          path: cloud-native-app/allure-report/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cloud-native-app-coverage-report
          path: cloud-native-app/reports/coverage/
          retention-days: 30
          if-no-files-found: warn

  react-playwright-demo:
    name: React Playwright Demo (TypeScript)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.module == 'all' || github.event.inputs.module == 'react-playwright-demo' || github.event_name != 'workflow_dispatch' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20.19.0'
      - name: Install Cursor CLI
        if: ${{ github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch' }}
        run: |
          curl https://cursor.com/install -fsS | bash
          echo "$HOME/.cursor/bin" >> $GITHUB_PATH
      - run: |
          # Install Node.js dependencies for react-playwright-demo
          cd react-playwright-demo
          if [ -f package.json ]; then 
            echo "Installing react-playwright-demo dependencies..."
            yarn install
          fi
          # Create reports directory in react-playwright-demo
          mkdir -p reports/allure-results reports/coverage
      - run: |
          cd react-playwright-demo
          if command -v yarn >/dev/null 2>&1; then yarn lint || true; fi
      - name: Run Tests with Allure Results and Coverage
        if: always()
        run: |
          cd react-playwright-demo
          # Create reports directory
          mkdir -p reports/allure-results reports/coverage
          
          # Run Jest tests with coverage
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            echo "Running Jest tests with coverage..."
            yarn test:coverage || true
          fi
          
          # Install Playwright browsers
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            echo "Installing Playwright browsers..."
            yarn playwright install --with-deps || true
          fi
          
          # Run Playwright tests with Allure reporting
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            echo "Running Playwright tests with Allure reporting..."
            yarn test:e2e || true
            
            # Debug Playwright test results
            echo "Checking for Playwright test results..."
            if [ -d "test-results" ]; then
              echo "test-results directory exists:"
              ls -la test-results/
            else
              echo "No test-results directory found"
            fi
            
            if [ -d "playwright-report" ]; then
              echo "playwright-report directory exists:"
              ls -la playwright-report/
            else
              echo "No playwright-report directory found"
            fi
            
            # Generate Playwright HTML report if it doesn't exist
            if [ ! -d "playwright-report" ] || [ ! "$(ls -A playwright-report)" ]; then
              echo "Generating Playwright HTML report..."
              # Run tests again with explicit HTML reporter to ensure report is generated
              yarn playwright test --reporter=html || true
            fi
            
            # Final check of Playwright report
            echo "Final Playwright report check:"
            if [ -d "playwright-report" ]; then
              echo "playwright-report directory exists:"
              ls -la playwright-report/
              echo "playwright-report file count:"
              find playwright-report/ -type f | wc -l || echo "0"
            else
              echo "playwright-report directory still does not exist"
            fi
            
            # Generate Allure report from Playwright results
            if [ -d "allure-results" ] && [ "$(ls -A allure-results)" ]; then
              echo "Installing Allure commandline..."
              npm install -g allure-commandline
              echo "Generating Allure report from Playwright results..."
              allure generate allure-results --clean -o reports/allure-report || true
              # Copy allure-results to reports/allure-results for consistency
              cp -r allure-results/* reports/allure-results/ || true
            else
              echo "No Playwright Allure results found"
            fi
          fi
          
          # Copy coverage to reports/coverage for consistency with other modules
          if [ -d "coverage" ] && [ "$(ls -A coverage)" ]; then
            echo "Copying coverage to reports/coverage for consistency..."
            mkdir -p reports/coverage
            cp -r coverage/* reports/coverage/
          fi
          
          # List generated files for debugging
          echo "Allure results directory contents:"
          ls -la reports/allure-results/ || echo "No Allure results generated"
          echo "Coverage reports directory contents:"
          ls -la reports/coverage/ || echo "No coverage reports generated"
          echo "Allure results file count:"
          find reports/allure-results/ -name "*.json" | wc -l || echo "0"
          echo "Sample Allure result files:"
          find reports/allure-results/ -name "*.json" | head -5 || echo "No Allure JSON files found"
      - name: Fix Test Failures with Cursor
        id: cursor-fixes
        if: failure() && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        env:
          CURSOR_API_KEY: ${{ secrets.CURSOR_API_KEY }}
        run: |
          echo "ðŸ”§ Cursor CLI: Analyzing and fixing test failures..."
          cursor-agent -p "IMPORTANT: Do NOT create branches, commit, push, or post PR comments. 
          Only modify files in the working directory. 
          Analyze the test failures in this CI run and fix the test files in the react-playwright-demo module. 
          This module uses TypeScript/Node.js with Jest and Playwright for testing.
          Focus on fixing TypeScript errors, Jest configuration issues, Playwright test issues, import errors, and test logic problems. 
          Ensure all tests can be collected and executed successfully."
      - name: Re-run Tests After Cursor Fixes
        if: always() && (steps.cursor-fixes.outcome == 'success' || steps.cursor-fixes.outcome == 'failure') && (github.event.inputs.enable_cursor_fixes != false || github.event_name != 'workflow_dispatch')
        run: |
          echo "ðŸ”„ Re-running tests after Cursor fixes..."
          cd react-playwright-demo
          if [ -f package.json ] && command -v yarn >/dev/null 2>&1; then
            # Install Playwright browsers before running tests
            echo "Installing Playwright browsers..."
            yarn playwright install --with-deps || true
            yarn test:coverage || true
            yarn test:e2e || true
          fi
      - name: Generate Allure Report
        if: always()
        run: |
          cd react-playwright-demo
          if [ -d "reports/allure-results" ] && [ "$(ls -A reports/allure-results)" ]; then
            echo "Installing Allure commandline..."
            # Install Allure using npm (more reliable than yarn global)
            npm install -g allure-commandline
            echo "Generating Allure report for react-playwright-demo..."
            allure generate reports/allure-results --clean -o reports/allure-report
            echo "Allure report generated successfully"
            # Verify the report was created
            if [ -d "reports/allure-report" ]; then
              echo "Allure report directory created successfully"
              ls -la reports/allure-report/
            else
              echo "ERROR: Allure report directory was not created"
            fi
          else
            echo "No Allure results found for react-playwright-demo"
          fi
      - name: Upload Allure Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: react-playwright-demo-allure-results
          path: react-playwright-demo/reports/allure-results/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Allure Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: react-playwright-demo-allure-report
          path: react-playwright-demo/reports/allure-report/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: react-playwright-demo-coverage-report
          path: react-playwright-demo/reports/coverage/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload Playwright Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: react-playwright-demo-playwright-report
          path: react-playwright-demo/playwright-report/
          retention-days: 30
          if-no-files-found: warn

  process-test-reports:
    name: Process Test Reports
    if: always()
    uses: ./.github/workflows/deploy-test-reports.yml
    with:
      module: all
    needs: [automation-framework, ai-rulesets, cloud-native-app, react-playwright-demo]

  deploy-reports:
    name: Deploy to GitHub Pages
    if: always()
    uses: ./.github/workflows/static.yml
    needs: [process-test-reports]
